{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project : Use ensemble methods and compare the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Medical Insurance Charges**\n",
    "\n",
    "The goal of this project is to predict an individual’s medical insurance charges based on various factors.\n",
    "\n",
    "Premiums for health insurance can vary based on lifestyle choices, health conditions, and other factors.\n",
    "\n",
    "I’d like to determine which factors are most influential towards insurances costs and have a model that will predict charges for individuals based on their attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data ##\n",
    "We'll use the dataset at https://www.kaggle.com/datasets/mirichoi0218/insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "dataset = \"mirichoi0218/insurance\"\n",
    "file_name = \"insurance.csv\"\n",
    "\n",
    "df = kagglehub.dataset_load(KaggleDatasetAdapter.PANDAS, dataset, file_name)\n",
    "raw = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    raw.shape,\n",
    "    raw.head(10),\n",
    "    raw.tail(10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(raw.isnull().sum())\n",
    "prev_shape = raw.shape\n",
    "raw = raw.dropna()\n",
    "shape = raw.shape\n",
    "if prev_shape == shape:\n",
    "    print(\"[INFO] shapes stayed the same after dropna() call\")\n",
    "else:\n",
    "    print(\"[WARN] shape changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = raw.drop_duplicates()\n",
    "\n",
    "display(\n",
    "    raw.info(),\n",
    "    raw.describe().T,\n",
    "    raw.duplicated().sum(),\n",
    "    raw.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see aggregated counts for cols\n",
    "cols = [\"children\", \"region\", \"sex\", \"smoker\"]\n",
    "for col in cols:\n",
    "    display(raw[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "raw.hist([\"age\", \"bmi\", \"charges\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "raw[\"charges\"] = np.log(raw[\"charges\"] + 1)\n",
    "sns.histplot(raw[\"charges\"])\n",
    "plt.title(\"charges log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw = pd.get_dummies(\n",
    "    raw, columns=[\"sex\", \"smoker\", \"region\"], drop_first=True, dtype=int\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(raw.corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlations of charges with smoker_yes and age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_corr = raw.copy()\n",
    "corr_matrix = raw_corr[[\"age\", \"smoker_yes\", \"charges\"]].corr()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation with Charges\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(\n",
    "    data=raw,\n",
    "    x=\"age\",\n",
    "    y=\"charges\",\n",
    "    scatter_kws={\"alpha\": 0.4},\n",
    "    line_kws={\"color\": \"red\"},\n",
    ")\n",
    "plt.title(\"Linear Relationship: Age vs Charges\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Charges\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=raw, x=\"smoker_yes\", y=\"charges\", hue=\"smoker_yes\", palette=\"Set2\")\n",
    "plt.title(\"Charges by Smoking Status\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import (\n",
    "    BaggingRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    "    StackingRegressor,\n",
    "    VotingRegressor,\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "numeric_features = [\"age\", \"bmi\", \"children\"]\n",
    "categorical_features = [\"sex\", \"smoker\", \"region\"]\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "\n",
    "X = df[numeric_features + categorical_features]\n",
    "X = df.drop(columns=[\"charges\"])\n",
    "y = df[\"charges\"]\n",
    "y_log = np.log1p(df[\"charges\"])\n",
    "\n",
    "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_log, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods/Models ##\n",
    "\n",
    "\n",
    "- BaggingRegressor\n",
    "- GradientBoostingRegressor\n",
    "- RandomForestRegressor\n",
    "- StackingRegressor\n",
    "- VotingRegressor\n",
    "\n",
    "We also have LinearRegression and KNNRegressor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "base_models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"Bagging\": BaggingRegressor(estimator=DecisionTreeRegressor(), random_state=42),\n",
    "    \"Stacking\": StackingRegressor(\n",
    "        estimators=[\n",
    "            (\"rf\", RandomForestRegressor(random_state=42)),\n",
    "            (\"gb\", GradientBoostingRegressor(random_state=42)),\n",
    "        ],\n",
    "        final_estimator=LinearRegression(),\n",
    "    ),\n",
    "    \"Voting\": VotingRegressor(\n",
    "        [\n",
    "            (\"lr\", LinearRegression()),\n",
    "            (\"rf\", RandomForestRegressor(random_state=42)),\n",
    "            (\"gb\", GradientBoostingRegressor(random_state=42)),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\n",
    "            \"cat\",\n",
    "            OneHotEncoder(drop=\"first\", sparse_output=False, handle_unknown=\"ignore\"),\n",
    "            categorical_features,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "param_grids = {\n",
    "    \"Gradient Boosting\": {\n",
    "        \"regressor__n_estimators\": [100, 200],\n",
    "        \"regressor__max_depth\": [3, 5],\n",
    "        \"regressor__learning_rate\": [0.05, 0.1],\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"regressor__n_estimators\": [100, 200],\n",
    "        \"regressor__max_depth\": [None, 10],\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        \"regressor__max_depth\": [None, 5, 10],\n",
    "        \"regressor__min_samples_split\": [2, 5],\n",
    "    },\n",
    "    \"Bagging\": {\n",
    "        \"regressor__n_estimators\": [10, 50],\n",
    "        \"regressor__max_samples\": [0.8, 1.0],\n",
    "    },\n",
    "}\n",
    "\n",
    "tuned_models = [\"Gradient Boosting\", \"Random Forest\", \"Decision Tree\", \"Bagging\"]\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for name in tuned_models:\n",
    "    model = base_models[name]\n",
    "    pipe = Pipeline([(\"preprocessor\", preprocessor), (\"regressor\", model)])\n",
    "\n",
    "    grid = GridSearchCV(pipe, param_grids[name], cv=5, scoring=\"r2\", n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_models[name] = grid.best_estimator_\n",
    "\n",
    "    print(f\"\\n{name} - Best R²: {grid.best_score_:.4f}\")\n",
    "    print(f\"Best Params: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Models ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(\n",
    "        max_depth=5, min_samples_split=2, random_state=42\n",
    "    ),\n",
    "    \"Random Forest\": RandomForestRegressor(\n",
    "        max_depth=10, n_estimators=200, random_state=42\n",
    "    ),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(\n",
    "        learning_rate=0.05, max_depth=3, n_estimators=100, random_state=42\n",
    "    ),\n",
    "    \"Bagging\": BaggingRegressor(\n",
    "        max_samples=0.8,\n",
    "        n_estimators=50,\n",
    "        estimator=DecisionTreeRegressor(),\n",
    "        random_state=42,\n",
    "    ),\n",
    "    \"Stacking\": StackingRegressor(\n",
    "        estimators=[\n",
    "            (\n",
    "                \"rf\",\n",
    "                RandomForestRegressor(max_depth=10, n_estimators=200, random_state=42),\n",
    "            ),\n",
    "            (\n",
    "                \"gb\",\n",
    "                GradientBoostingRegressor(\n",
    "                    learning_rate=0.05, max_depth=3, n_estimators=100, random_state=42\n",
    "                ),\n",
    "            ),\n",
    "        ],\n",
    "        final_estimator=LinearRegression(),\n",
    "    ),\n",
    "    \"Voting\": VotingRegressor(\n",
    "        [\n",
    "            (\n",
    "                \"rf\",\n",
    "                RandomForestRegressor(max_depth=10, n_estimators=200, random_state=42),\n",
    "            ),\n",
    "            (\n",
    "                \"gb\",\n",
    "                GradientBoostingRegressor(\n",
    "                    learning_rate=0.05, max_depth=3, n_estimators=100, random_state=42\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "best_r2 = -float(\"inf\")\n",
    "best_rmse = float(\"inf\")\n",
    "best_model_r2 = None\n",
    "best_model_rmse = None\n",
    "feature_importances = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline([(\"preprocessor\", preprocessor), (\"regressor\", model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "\n",
    "    preds_original_scale = np.exp(preds)\n",
    "    y_test_original_scale = np.exp(y_test)\n",
    "\n",
    "    r2 = r2_score(y_test_original_scale, preds_original_scale)\n",
    "    rmse = mean_squared_error(y_test_original_scale, preds_original_scale) ** 0.5\n",
    "    mae = mean_absolute_error(y_test_original_scale, preds_original_scale)\n",
    "\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_model_r2 = name\n",
    "\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_model_rmse = name\n",
    "\n",
    "    print(f\"\\n{name} - Predictions:\")\n",
    "    print(f\"r2: {r2:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(\"\\nPredictions vs Actuals:\")\n",
    "\n",
    "    comparison = pd.DataFrame(\n",
    "        {\"Actual\": y_test_original_scale, \"Predicted\": preds_original_scale}\n",
    "    )\n",
    "    print(comparison.head())\n",
    "\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        feature_importances[name] = model.feature_importances_\n",
    "\n",
    "print(f\"\\nBest Model by r2: {best_model_r2} with r2 = {best_r2:.4f}\")\n",
    "print(f\"\\nBest Model by RMSE: {best_model_rmse} with RMSE = {best_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation\n",
    "# highest R^2 and lowest RMSE\n",
    "\n",
    "model_r2_scores = {}\n",
    "model_rmse_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline([(\"preprocessor\", preprocessor), (\"regressor\", model)])\n",
    "\n",
    "    r2_scores = cross_val_score(pipe, X, y, cv=5, scoring=\"r2\")\n",
    "    rmse_scores = cross_val_score(\n",
    "        pipe, X, y, cv=5, scoring=\"neg_root_mean_squared_error\"\n",
    "    )\n",
    "\n",
    "    model_r2_scores[name] = r2_scores.mean()\n",
    "    model_rmse_scores[name] = -rmse_scores.mean()\n",
    "\n",
    "    print(f\"\\n{name} - Cross-Validation Results:\")\n",
    "    print(f\"Mean R²: {model_r2_scores[name]:.4f}\")\n",
    "    print(f\"Mean RMSE: {model_rmse_scores[name]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# highest R^2 and lowest RMSE\n",
    "\n",
    "r2_scores = []\n",
    "rmse_scores = []\n",
    "model_names = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline([(\"preprocessor\", preprocessor), (\"regressor\", model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "\n",
    "    r2_scores.append(r2)\n",
    "    rmse_scores.append(rmse)\n",
    "    model_names.append(name)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "ax[0].barh(model_names, r2_scores, color=\"skyblue\")\n",
    "ax[0].set_title(\"r2 Scores\")\n",
    "ax[0].set_xlabel(\"r2\")\n",
    "ax[0].set_ylabel(\"Model\")\n",
    "\n",
    "ax[1].barh(model_names, rmse_scores, color=\"salmon\")\n",
    "ax[1].set_title(\"RMSE Scores\")\n",
    "ax[1].set_xlabel(\"RMSE\")\n",
    "ax[1].set_ylabel(\"Model\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, importances in feature_importances.items():\n",
    "    if importances is not None:\n",
    "        if \"Stacking\" not in name and \"Voting\" not in name:\n",
    "            encoded_columns = preprocessor.transformers_[1][1].get_feature_names_out(\n",
    "                categorical_features\n",
    "            )\n",
    "            all_columns = numeric_features + list(encoded_columns)\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.barh(all_columns, importances)\n",
    "            plt.xlabel(\"Importance\")\n",
    "            plt.title(f\"Feature Importances for {name}\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations\n",
    "\n",
    "### Linear Regression\n",
    "- **R²**: 0.7181  \n",
    "- **RMSE**: 7197.03  \n",
    "- **MAE**: 3755.92  \n",
    "- Weakest performance overall with lowest R² and highest RMSE.  \n",
    "- Systematically underestimates high charges; struggles with non-linearity.\n",
    "\n",
    "###  Decision Tree\n",
    "- **R²**: 0.8981  \n",
    "- **RMSE**: 4326.17  \n",
    "- **MAE**: 2090.06  \n",
    "- Strong accuracy, though may overfit on some predictions.\n",
    "\n",
    "###  Random Forest\n",
    "- **R²**: 0.8972  \n",
    "- **RMSE**: 4345.64  \n",
    "- **MAE**: 2051.15  \n",
    "- Generalizes better than a single tree, with close tracking of actual values.\n",
    "\n",
    "###  Gradient Boosting\n",
    "- **R²**: 0.8970  \n",
    "- **RMSE**: 4349.60  \n",
    "- **MAE**: 2053.86  \n",
    "- Smooth and consistent predictions, slightly below top performers.\n",
    "\n",
    "###  Bagging\n",
    "- **R²**: 0.8974  \n",
    "- **RMSE**: 4342.37  \n",
    "- **MAE**: 2072.77  \n",
    "- Strong results, slightly more stable than a single Decision Tree.\n",
    "\n",
    "###  Stacking\n",
    "- **R²**: 0.9030 *(Best)*  \n",
    "- **RMSE**: 4221.49 *(Best)*  \n",
    "- **MAE**: 1982.50  \n",
    "- Best model overall with highest R² and lowest RMSE.  \n",
    "- Excellent accuracy and generalization.\n",
    "\n",
    "###  Voting\n",
    "- **R²**: 0.9003  \n",
    "- **RMSE**: 4279.51  \n",
    "- **MAE**: 1987.56  \n",
    "- Nearly matches Stacking; consistent and reliable predictions.\n",
    "\n",
    "---\n",
    "\n",
    "###  **Best Model: Stacking**\n",
    "- Highest R²: **0.9030**\n",
    "- Lowest RMSE: **4221.49**\n",
    "- Lowest MAE: **1982.50**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x=\"smoker\", y=\"charges\", data=df)\n",
    "plt.title(\"Insurance Charges by Smoker Status\")\n",
    "plt.xlabel(\"Smoker\")\n",
    "plt.ylabel(\"Charges\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(\n",
    "    data=df,\n",
    "    x=\"charges\",\n",
    "    hue=\"smoker\",\n",
    "    kde=True,\n",
    "    element=\"step\",\n",
    "    stat=\"density\",\n",
    "    common_norm=False,\n",
    ")\n",
    "plt.title(\"Charges by Smoker Status\")\n",
    "plt.xlabel(\"Charges\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "df_corr = pd.get_dummies(\n",
    "    df, columns=[\"sex\", \"smoker\", \"region\"], drop_first=True, dtype=int\n",
    ")\n",
    "\n",
    "sns.heatmap(df_corr.corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Smoking highly correlated to charges*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "- **Stacking** and **Gradient Boosting** show the best performance for predicting charges.\n",
    "- **Smoking** appears to contribute significantly to charges and we see a high correlation of 0.79 approaching 1.\n",
    "- *Age* contributes to charges. This makes sense as an individual's health deteriorates over time.\n",
    "- To a lesser extent, *BMI* contributes to charges.\n",
    "\n",
    "If you smoke, stop as soon as you can and if you're BMI is high, take steps to lower it -- because you can't control age."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
